<!DOCTYPE html>
<html lang="">
    
  <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.74.0" />

    

<title>Astro Data Group</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="The Astronomical Data Group"/>
<meta name="twitter:description" content="The Astronomical Data Group at The Center for Computational Astrophysics, Flatiron Institute, Simons Foundation in New York City"/>

<meta property="og:title" content="The Astronomical Data Group" />
<meta property="og:description" content="The Astronomical Data Group at The Center for Computational Astrophysics, Flatiron Institute, Simons Foundation in New York City" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://astrodata.nyc/" />
<meta property="og:updated_time" content="2020-10-19T00:00:00+00:00" /><meta property="og:site_name" content="The Astronomical Data Group" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">








<link rel="stylesheet" href="/scss/hyde-hyde.d773a8586cc36238913d8ca94a29183adfd13d11dad198ae076b377ab46e3f23.css" integrity="sha256-13OoWGzDYjiRPYypSikYOt/RPRHa0ZiuB2s3erRuPyM=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    <link rel="alternate" type="application/rss+xml" href="https://astrodata.nyc/index.xml" title="Astro Data Group" />

    

</head>


    <body class="theme-base-08 ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://astrodata.nyc/">Astro Data Group</a>
      </span>
      
      
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Astro Data Group</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/">
						<span>Home</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/about/">
						<span>About</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	<a href="https://twitter.com/FlatironCCA" rel="me"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a>
	
	
	
	<a href="https://github.com/astrodatagroup" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
</section>

      </div>
    </div>
    
<div class="copyright">
  &copy; 2020 astrodatagroup
  
    <a href="https://creativecommons.org/licenses/by/4.0">CC-BY</a>
  
</div>



  </div>
</div>

        <div class="content container">
            
  <div class="post-list">
    
    
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-10-19-kicbinaries/" >Finding Unresolved Stellar Companions in Kepler Planet Hosts with Gaia</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Oct 19, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/quadry-chance">Quadry Chance</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-10-19.png" alt="img"></p>
<p>At this week’s meeting, I updated the group about my project with D F-M, Andy Casey (Monash University), and Tim Morton (USC- the west coast one). We are looking into how to determine how the binarity of Kepler planet hosts influence planet formation. That sounds really exciting but “determine” is doing a lot of work in that sentence. First, we have to figure out which stars are (unresolved) binaries. There are a couple of different ways in which we’ll go about doing this, but the one highlighted this week is the fruit of Andy’s work.</p>
<p>Alongside the astrometric and RV measurements, Gaia also lists errors associated with fits. For unresolved binaries, trying to fit the astrometric or RV curve of a single star will yield an uncharacteristically large amount of error. Through Andy’s work (which I can’t claim to understand beyond the surface level), we can turn this error into a likelihood that the star is not a single star.</p>
<p>Incredibly, this seems to work really well! In the color-magnitude diagram above of the KIC stars with astrometric measurements, we can pick out the stars that have a low probability of being single above the main sequence; right where we would expect binaries to be.</p>
<p>Interestingly, the same plot for KIC stars with RV measurements looks very different. There are a few selection effects here we’ll have to figure out: not all stars have both astrometric and  RV measurements and (as pointed out by Trevor) the population of binaries detected by astrometry is different from that of RV binaries. Known spectroscopic and eclipsing binaries are picked up through RV jitter but not astrometric jitter!</p>
<p>Figuring out how exactly accurate this is will be key. Because neither method is batting 1.000, exactly how to quantify “I’m pretty sure this star is not a single” represents an interesting puzzle for our near-future selves.</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-10-09-pytorch-difference-imaging/" >GPU-accelerated difference imaging</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Oct 9, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/dan-f-m">Dan F-M</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-10-09.png" alt="img"></p>
<p>At this week&rsquo;s meeting I shared an update about a project called <a href="https://github.com/jah1994/PyTorchDIA">PyTorchDIA</a> led by James Hitchcock (St. Andrews) where we are looking into how numerical tools developed for machine learning can be applied to astronomy.
Unlike many applications of PyTorch, TensorFlow, etc. in astronomy, I&rsquo;m not talking about <em>using</em> neural networks.
Instead, I&rsquo;m talking about using PyTorch to compute fast convolutions and matrix-vector products to accelerate more &ldquo;traditional&rdquo; astronomy problems.
This is somewhat similar in spirit to the <a href="https://github.com/megbedell/wobble/">wobble</a> project led by Megan Bedell (that strangely has never appeared on this blog, Megan!).</p>
<p>For the PyTorchDIA project, James and I realized that we might be able to easily port <a href="https://arxiv.org/abs/astro-ph/9712287">existing difference imaging methods</a> to run on the GPU using PyTorch since the bottleneck operation is solving a large linear problem where the design matrix is a convolution.
This is exactly the type of operation encountered in deep learning applications and exactly what frameworks like <a href="https://pytorch.org">PyTorch</a> are designed for.
James took this one step further, and instead of directly solving this linear system, he uses an iterative solver that only requires matrix-vector products (rather than a full Cholesky factorization).
This allows us to relax some of the assumptions (like Gaussianity of the observation model) of the standard methods so that we can use a robust loss function instead of sigma clipping.</p>
<p>Using the GPUs available on <a href="https://colab.research.google.com">Google Colab</a>, James finds that his method is at least an order of magnitude faster than optimized implementations of other commonly used methods for difference imaging, across a wide range of realistic test cases.
We will hopefully be submitting this paper in the next week or so and we are already planning on incorporating this method into the pipelines for several existing and upcoming difference imaging surveys.
But, the real reason why I shared this with the group was that I believe that there are some (potentially) useful lessons learned:</p>
<ol>
<li>Astronomical imaging analysis shares a lot of structure with machine learning problems; let&rsquo;s take advantage of that!</li>
<li>Some of the linear problems that we work on in the group might be easier and faster to solve if we use iterative solvers rather than direct solvers. The scaling is different, but also the implementations have been optimized for the forward calculation and these methods can open the possibility of generalizing the loss function.</li>
</ol>
<p><em>Aside:</em> I also want to mention the awesome website <a href="https://weirdgalaxi.es">weirdgalaxi.es</a> (yes that is the domain name, but don&rsquo;t click on that if you&rsquo;re using Safari) that Kate Storey-Fisher made (and shared at this week&rsquo;s meeting) as a continuation of the project that <a href="https://astrodata.nyc/posts/2019-08-23-anomalies/">she previously blogged about</a>.</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-10-02-binaries/" >APOGEE &#43; COSMIC =? &lt;3</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Oct 2, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/katie-breivik">Katie Breivik</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-10-02.jpg" alt="img"></p>
<p>After arriving at CCA a few weeks ago, I&rsquo;m starting on a project with Adrian Price-Whelan and David W. Hogg.
We are trying to figure out how to answer the question: What does it mean that APOGEE doesn&rsquo;t have a bunch of binary systems containing black holes?
Barring the obvious reason that APOGEE&rsquo;s targets are low-ish mass stars and thus unlikely to be companions to BHs and their high-mass progenitors, we think it will be interesting to compare a bunch of synthetic binary populations generated with <a href="https://cosmic-popsynth.github.io/">COSMIC</a> to Adrian&rsquo;s <a href="https://ui.adsabs.harvard.edu/abs/2020ApJ...895....2P/abstract">close binary catalog</a>.</p>
<p>Step 0 of this process is to work out how to generate mock APOGEE catalogs with COSMIC data.
This means I need to do real astronomy to convert the effective temperatures and bolometric luminosities in my simulations to (gasp) magnitudes of both the absolute and apparent kind.
Luckily for me we found Tim Morton&rsquo;s <a href="https://isochrones.readthedocs.io/en/latest/">isochrones</a> package that provides interpolated bolometric corrections from the MIST bolometric correction tables.
The figure above shows a CMD that I made from a little test sample of a few synthetic binaries that follow the age and metallicity distribution of the m12i galaxy in the <a href="https://fire.northwestern.edu/milky-way/">Latte Suite</a> of the <a href="https://fire.northwestern.edu/">FIRE</a> cosmological simulations.
I was pretty excited to see the suuper obvious double main sequence and that COSMIC produced something that looks somewhat similar to what you&rsquo;d expect (see e.g. Fig 5 <a href="https://arxiv.org/pdf/2002.00014.pdf">here</a>).</p>
<p>Steps 1 onward will include picking which kinds of binary interactions will most severely impact a BH + star population that APOGEE can see (hello BH natal kicks!) to set up our binary evolution model set and including dust extinction.
I&rsquo;m sure eventually I will also open real astro data files that at some point intheir distant post-processing past came from telescopes!</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-09-27-extrabol/" >Estimating the Bolometric Light Curves of Supernovae</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Sep 27, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/v.-ashley-vilar">V. Ashley Vilar</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-09-27.png" alt="img"></p>
<p>I’ve been working (slowly but surely) on an open source code <a href="https://pypi.org/project/extrabol/">extrabol</a> which estimates the bolometric light curves of supernovae from an arbitrary set of filtered photometric observations. This code is based on a package by Matt Nicholl, <a href="https://pypi.org/project/SuperBoL/">SuperBoL</a>.</p>
<p>Estimating the bolometric luminosity and black body temperature of a supernova is an extremely common analysis problem in time-domain astronomy as it allows astronomers to easily probe supernova explosion dynamics. Unfortunately, supernova light curves are often poorly sampled across multiple photometric filters, making it challenging to build a pseudo-bolometric light curve directly from the data.</p>
<p>In order to solve this problem, extrabol uses a 2D Gaussian process to extrapolate the supernova spectral energy distribution (SED) as a function of both wavelength and time. Extrabol is linked to the Spanish Virtual Observatory, a database of nearly every commonly used astronomical filter. Given the name of a telescope/filter, extrabol will link the observation to an effective wavelength. Using an arbitrary set of filters from the user, extrabol will estimate the underlying SED and then use this SED to estimate a black body temperature and radius. Eventually, the goal is to have extrabol linked with the Open Supernova Catalog, so that a user type in the name of a supernova and quickly build a bolometric light curve using public data.</p>
<p>For now, I am still working out some bugs! The Figure above shows an example light curve for a core-collapse supernova. Each observation is shown as a point (with error bars being smaller than the points). The GP interpolation is shown as lines, with uncertainty shown as shaded regions. Currently, I am assuming a mean function of a very dim magnitude, which works well before and after the supernova itself; however, if there is a large gap of data, the GP prefers artificially low luminosities. I got some very useful feedback from the Astro Data Group this week to investigate a more physically meaningful mean function, with <em>residuals</em> being modeled by the GP. My next step is figuring out if there is such a function which can be used for all flavors of supernovae!</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-09-18-emu-fight/" >The Great Emu Fight</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Sep 18, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/kate-storey-fisher">Kate Storey-Fisher</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-09-18.png" alt="img"></p>
<p>At <a href="http://astrohackweek.org/2020/">AstroHackWeek 2020</a> last week, a fight broke out - not between the supportive and friendly participants, but between emulators. I pitched a hack project on comparing emulation methods, mostly so I could show <a href="https://www.youtube.com/watch?v=d9OBqYbZ99c">this emu vs. kangaroo fight video</a> during my pitch, and a <a href="https://github.com/kstoreyf/emu-fight/blob/master/images/authors_fighting.png">team of fighters</a> assembled. <em>All credit for this project shared with Catarina Alves, Johannes Heyl, Yssa Camacho-Neves, and Johnny Esteves!</em></p>
<p>One of my research projects is on emulating galaxy clustering statistics for speedier, more accurate inference of cosmological and assembly bias parameters. I had been wanting to try out different emulation methods on this data, as well as write up a pedagogical tutorial on emulation. In brief, emulators are regressors that imitate more complex models or simulations. They are trained on a limited set of simulation inputs and output and learn the layout of this (often high-dimensional) parameter space; then for any new set of inputs, they can quickly spit out output values, without performing a physical calculation or a full simulation.</p>
<p>Our hack team first wrote up a detailed explanation of emulators, complete with an example about a computational emu biologist; check it out in <a href="https://nbviewer.jupyter.org/github/kstoreyf/emu-fight/blob/master/the_great_emu_fight.ipynb">our complete tutorial here</a>. Then we wanted to actually build some emulators and test them on astronomical data. My full-scale research dataset proved unwieldy for a week-long project, so I generated a set of two-point correlation functions using <code>nbodykit</code>. The winning emulator should be able to take the input values of (Omega_m, sigma_8, Omega_b) and predict the correlation function in each of 10 separation bins.</p>
<p>Each team member took on a different emulation framework. So far, our lineup includes an Artifical Neural Network, a Random Forest, a Decision Tree, and a Support Vector Machine (with Gaussian Processes on the way). The fighters tuned their implementations and hyperparameters to the best of their abilities. The fight was heated, with the emulators racing to train and test out their clustering predictions. You can see the predictions of the SVM compared to the true correlation function in the figure above.</p>
<p>To see the outcome, you&rsquo;ll have to follow the full battle at <a href="https://nbviewer.jupyter.org/github/kstoreyf/emu-fight/blob/master/the_great_emu_fight.ipynb">The Great Emu Fight notebook</a>. But the takeaways were:</p>
<ul>
<li>The Support Vector Machine emerged as the clear winner in accuracy for every metric we tested, emulating the correlation function to within a tenth of a percent for most r-bins. The Artificial Neural network came in a close second. (The second figure above shows the R^2 error; you can see the large difference in accuracy between the SVM and ANN compared to the DTree and RF.)</li>
<li>However, the SVM was by far the slowest to train. The Decision Tree handily won the training round.</li>
<li>The Decision Tree and the ANN were the winners when it came to prediction time (this is super important for inference!).</li>
<li>The Random Forest was an all-around loser, being very slow at prediction and sadly inaccurate; we love and appreciate it anyway.</li>
<li>Most importantly, all of these results are super dependent on emulator implementation, hyperparameter tuning, data normalization, and the dataset itself! So the reigning champion likely won&rsquo;t reign for long.</li>
<li>We built this project to be incredibly modular, so you can throw your own emulator or dataset into the ring. Follow one of our <a href="https://github.com/kstoreyf/emu-fight/tree/master/emulator_examples">standalone notebook tutorials</a> and tune the hyperparameters to improve on our results, or <a href="https://github.com/kstoreyf/emu-fight#contributing">add in your own complete implementation</a>, and join in the fight.</li>
</ul>
<p><em>Check out the project in <a href="https://github.com/kstoreyf/emu-fight">this repo</a>, and follow the complete fight at <a href="https://nbviewer.jupyter.org/github/kstoreyf/emu-fight/blob/master/the_great_emu_fight.ipynb">The Great Emu Fight notebook</a>. Huge thank you to the emu-fight team and the AstroHackWeek organizers!</em></p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-09-11-big-meetings/" >How do people run big group meetings?</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Sep 11, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/dan-f-m">Dan F-M</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p>Last week we had our first meeting of the new semester and we decided to try something &ldquo;new&rdquo;.
In fact we went back to how we ran things back in the olden days: we take the total meeting time and divide it equally between people who are online, and everyone gives an update.
In many ways, this is really how we <em>want</em> group meeting to go.
The whole point is that, since group members work on such a broad range of topics, we want to have an opportunity to hear what everyone else has been up to.
The goal is to identify shared interests and encourage collaborations across research areas.</p>
<p>This time (unlike the olden days), we had 18 group members (or collaborators working actively on a project with a group member) online (and that isn&rsquo;t even the whole group these days - I&rsquo;m not complaining!).
This meant that even with 90 minutes, the updates had to be very short and the whole thing felt like quite a whirlwind (and I needed to take a nap after logging off).
As a result, I&rsquo;m not going to write up a summary of all the awesome work that folks are doing.
Instead, I want to ask if anyone has advice or thoughts about running big group meetings like this.</p>
<p>Overall, it seems like the group appreciated this format, but agrees that it might be a bit overwhelming to do it every week.
So the current plan is to proceed with the format from the summer (a shared slide deck where group members can choose to add a slide and then share a 10 minute update with some discussion) for most meetings, and then about once a month we would have a whirlwind update from everyone.
I don&rsquo;t love this option, because this meeting is often the only time that I get updates from many group members.
But, we haven&rsquo;t been able to identify a format that helps to make sure that everyone gets and opportunity to share.
We&rsquo;d love to hear if there are other groups out there doing interesting things with their meetings.
We&rsquo;re always keen to try experiments, especially since we&rsquo;ll be staying fully-remote for the foreseeable future!</p>
<p>If you have thoughts, please <a href="https://twitter.com/exoplaneteer">Tweet at me</a> or send me an email (should be <a href="https://www.simonsfoundation.org/team/daniel-foreman-mackey/">easy to find</a>!)</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-08-28-summary-08-28/" >Summary, August 28, 2020</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Aug 28, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/dan-f-m">Dan F-M</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-08-28.png" alt="img"></p>
<p>Jiayin Dong (DJ) updated us on her project to study the eccentricity distribution of warm-Neptune exoplanets discovered using data from the TESS mission.
She has discovered and carefully characterized about 100 of these transiting planets.
She then uses the &ldquo;photoeccetric effect&rdquo; to infer the distribution of eccentricities based on the observed distribution of effective &ldquo;circular stellar densities&rdquo;.
The inferred distribution is the <em>observed</em> population of orbital eccentricities but, if the detectability of the planet is correlated with eccentricity, this won&rsquo;t necessarily be equivalent to measuring the true intrinsic eccentricity distribution.
This will be an important effect (eccentricity will scale with orbital period and the probability that a planet transits is also a function of its eccentricity), so DJ asked the group for recommendations about how to take this into account.
This led to a discussion about &ldquo;inverse detection efficiency&rdquo; methods versus likelihood-based methods for population inference.
(<a href="https://dfm.io/posts/histogram1/">I have opinions about this</a>&hellip; I&rsquo;m writing this post so I&rsquo;m allowed to editorialize!)</p>
<p>Next, John Forbes shared a data analysis challenge where he has a simulation of a forming galaxy where he has snapshots of several quantities that, to order of magnitude, should sum to satisfy a differential equation.
In practice, because of numerics and approximations this differential equation is not exactly satisfied, so he is interested in fitting for, possibly time and space invariant, offsets or scales for each of these quantities to best fit the constraints.
Currently, he is using linear least squares to fit for multiplicative factors (that don&rsquo;t depend on time or position) for each quantity, but finds that the results are not satisfactory.
Several suggestions were made for relaxing these assumptions and fitting a more flexible model.
One option would be to fit multiple galaxies together (in some sort of hierarchical model) to propagate information between them.
Another would be to allow use a Gaussian Process either to model residuals away from the least squares model or as priors on the coefficients that enforce smoothness in time and space.</p>
<p>Then, Daivd W. Hogg shared a first draft of a <em>Mission Statement</em> and <em>5-Year Plan</em> for the Astronomical Data Group.
These highlight some of the things that we think we do well (encourage better data analysis practices, develop and support open source software, etc.), but also identify some of the places where we want to spend more energy.
The goal is to use these documents to help focus research areas and other group efforts, as well as hiring decisions.</p>
<p>Finally, I gave an update on the <a href="https://online.tess.science">online.tess.science</a> event (hackathon/sprint/something) that I am co-organizing.
It starts on Sept 8 (just over one week from now!) and there will be nearly 150 participants from around the world.
The header figure for this post shows the times that each participant is planning on being online during the 48 hours of the event - this really is a global experiment!
We are working to find the right balance of unstructured, asynchronous time and synchronous social/networking/check-in time with the goal of encouraging participants to meet a broad range of other community members.
Much of this, as well as our recommendations for how to navigate an event like this, is being codified in a &ldquo;Participant Handbook&rdquo; that I&rsquo;ve drafted with my co-organizers.
I expect that this document will continue to be useful for future events, even if they are in-person.</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-08-14-summary-08-14/" >Summary, August 14, 2020</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Aug 14, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/dan-f-m">Dan F-M</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p>I started this week&rsquo;s meeting by asking for feedback about our plans for the
<a href="https://online.tess.science">online.tess.science</a> event that I am co-organizing
in September. This event is the 2020 version (hopefully this is just a year, and
not an indication that it will go up in flames) of the
<a href="https://tess.science">tess.science</a> series of workshops where astronomers get
together to collaborate on new projects related to NASA&rsquo;s TESS mission. The
previous 3 events have all been organized in-person and, since this event will
be fully remote and international, there are various challenges (and
opportunities) that we haven&rsquo;t experienced before. One difference between this
event and many other online conferences is that there will be no formal
presentations. Instead, participants are encouraged to start new collaborations
and try to learn something new. The group had a lot of good questions and
feedback about our current plans. In particular, there was a good discussion
about how important it will be to manage expectations, especially when people
have experience with in-person events where they can walk across the room and
ask questions of any other participant in real time. There were also some
suggestions about how to encourage interactions between participants even if
they are not directly collaborating. We&rsquo;ll see how well we can execute on these
plans!</p>
<p>Next, John Forbes discussed a data management/coding challenge that he&rsquo;s
currently facing. He has a large simulation where the properties of a set of
about a million &ldquo;particles&rdquo; are saved to disk at a series of &ldquo;times&rdquo;. The output
of this simulation can be thought of as a large multidimensional array where the
first dimension is time, the second dimension is particle number, and the third
indexes the various properties that are being tracked. This full dataset is too
large to be loaded into memory and John wants to run an analysis on a subset of
the most interesting particles at all times. However, since the data are stored
as snapshots, loading the properties of a particular particle at all times is a
computationally expensive task. Besides a few snarky comments about
serialization formats, the group had several suggestions for how to improve this
performance of this operation. The main observation was that the data are
essentially stored in row-major order, while the operations would be more
efficient on column-major ordered data. The group suggested several tools that
could help here, including <a href="https://dask.org/">dask</a>,
<a href="https://parquet.apache.org/">Parquet</a>, and <a href="https://arrow.apache.org/">Arrow</a>.</p>
<p>And that was it&hellip; it is August, after all!</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-08-07-summary-08-07/" >Summary, August 7, 2020</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Aug 7, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/megan-bedell">Megan Bedell</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 2 min read
</div>


        </header>
        <div class="post">
          <p><img src="/fig/2020-08-07.png" alt="img"></p>
<p>We had a quiet but interesting group meeting this week!</p>
<p>First, Trevor David shared some recent work with Gaby Contardo on looking at the exoplanet radius gap as a function of host star age and asked for feedback on methods for quantifying the gap width.
He presented a few possible approaches, including fitting Gaussians to the 1D histogram of radii; fitting a line in the 2D radius-age plane by inverting the likelihood; or using a support vector machine model.
We spent some time discussing what assumptions are being made in each of these cases.
In particular, there was some debate about the validity of assuming Gaussian shapes for each of the two radius peaks.
We also discussed the related problem of assigning individual planets to different sides of the radius gap.
It might be necessary to perform the classification of data points in tandem with the characterization of the resulting gap in the distribution.</p>
<p>Next, Kate Storey-Fisher showed us an unusual galaxy in the Hyper-Suprime Cam data (pictured above).
The HSC image of this galaxy was flagged by Kate&rsquo;s GAN-based anomaly detection code, and archival data from Subaru and HST support its weirdness.
Kate recently obtained a follow-up spectrum from Keck and she showed that the resulting placement of the source on the <a href="https://ned.ipac.caltech.edu/level5/Glossary/Essay_bpt.html">BPT diagram</a> classifies it as a star-forming galaxy rather than an AGN.
However, there are still some oddities, including possible markers of strong outflows.
We spent time squinting through our Astronomer Goggles (TM) at the images and making extensive use of Zoom&rsquo;s markup features.
It&rsquo;s always fun to dig into the data during data group meeting!</p>
<p>Finally, David W. Hogg showed us one of his quarantine projects: learning how to execute a <a href="https://en.wikipedia.org/wiki/Faro_shuffle">perfect shuffle</a>.
He demonstrated that eight perfect shuffles in a row returns your deck of cards to the original ordering.
This means that the permutation matrix corresponding to a perfect shuffle has the property that raising it to the eighth power returns the identity matrix.
Linear algebra: it&rsquo;s everywhere!
We had a wide-ranging discussion covering combinatorics, psychology, and the entropy state of the universe.
Our only real conclusion was that when playing poker with Hogg, you should insist on cutting the deck between shuffles.</p>

        </div>
      </article>
     
    
      
    
    <article>
        <header>
          <h1><a href="/posts/2020-07-31-summary-07-31/" >Summary, July 31, 2020</a></h1>
          
          
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Jul 31, 2020
    
      
    
      
      
          by
          
          
              <a class="badge badge-category" href="/authors/dan-f-m">Dan F-M</a>
              
          
      
    
    
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 4 min read
</div>


        </header>
        <div class="post">
          <p>We started this week&rsquo;s meeting by discussing the possibility of organizing shared group meetings with other groups within CCA or within the broader astronomical community.
While this group is focused on methodology, the scientific interests are broad so it could be useful to occasionally join forces with groups focused on specific research areas of interest to group members.
It could also be useful as a method for encouraging random encounters between researchers who don&rsquo;t normally overlap, especially while working remotely.
Not everyone was completely enthusiastic about the idea, however, since there are already opportunities for group members to attend multiple group meetings within CCA and it might not be ideal to lose our one weekly meeting with the full group.
It looks like we will try a test run with another group at CCA and, after that, consider options for future experiments like this.</p>
<p>Next, Ruth Angus asked for feedback on the project that she is proposing to the NSF Career program.
She will be focusing on inferring rotation periods for stars using time series using data from the Zwicky Transient Factory and the Vera Rubin Observatory.
There are many technical details from a time domain analysis side that she has been working hard on, but she was asking for feedback on the potential use cases for a huge catalog of rotation periods and gyrochronological ages for faint Milky Way stars.
The group had many suggestions for applications and there was a good discussion of the project.</p>
<p>Rodrigo Luger talked about (gasp!) spherical harmonic representations of stellar surfaces and the resulting light curves.
Building on the work <a href="/posts/2020-07-24-summary-07-24/">he discussed last week</a>, Rodrigo has worked out a better parameterization for the spherical harmonic expansion of spots on the stellar surface.
He finds that if he parametrizes the spot using a Legendre polynomial expansion, all the spherical harmonic math that he needs to compute light curves turns out to be simple and the expansion of the spot is better behaved (no ringing and not going negative) than before.
Furthermore, he has demonstrated that the time series Gaussian Process that he presented last week is the Gaussian density with the minimum <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">K-L divergence</a> to the distribution over stars with discrete spots.
This has some interesting connections to <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational inference</a>.</p>
<p>Then, John Forbes shared a project where he is studying metal enrichment in Upper Scorpius.
The data analysis problem that he presented is that he needs to infer the distances between a handful of stars and a specific molecular cloud, the potential site of enrichment.
The projected distance (in the plane of the sky) is well measured, but John really needs the physical 3-dimensional distance and these stars only have noisy distance (from us) measurements.
Therefore, he needs to marginalize over the line-of-sight distance when estimating his quantity of interest and he&rsquo;s finding that the results are somewhat sensitive to his choice of prior for the 3-dimensional distribution of stars.
There was some discussion about ideas for understanding this effect and making the best choices, but this conversation will have to also continue offline.</p>
<p>Adrian Price-Whelan and Christina Hedges updated the group on the <a href="/posts/2020-07-17-summary-07-17/">project that they shared two weeks ago</a>, where they had discovered a new young, nearby moving group.
Since that meeting they have expanded their sample to include fainter and brighter stars that don&rsquo;t have radial velocity measurements in the Gaia catalog.
To determine membership probabilities, Adrian and Christina have implemented a probabilistic model that marginalizes over radial velocity when it is not measured.
The resulting catalog has some contamination that can be removed using the <code>RUWE</code> metric from the Gaia pipeline.
There are several bright (apparent magnitude of ~3) stars included in the cleaned sample and many fainter stars.
The age estimates from isochrones, lithium abundance, and high-resolution spectroscopy all consistently suggest an age of about 200 Myr, but the new sample includes a non-trivial number of white dwarfs, which is a bit puzzling at that age.
The suggestion was made that rotation periods might provide another good age estimate.</p>
<p>Finally, Sam Grunblatt asked for suggestions because he is running out of hard drive space for a project where he is currently generating millions of data files (including figures).
There was some discussion of the relative merits of binary vs. ASCII formats for data products (use binary!), but Sam&rsquo;s main issue is the huge number of plots that he&rsquo;s saving.
He generates these figures to make it faster and easier to page through and vet the results of a planet search using TESS.
But, going forward he would like to automate this further so the recommendation was made that he avoid saving these figures for every target, restricting instead to the most &ldquo;interesting&rdquo; ones.</p>

        </div>
      </article>
     
  </div>
  

<ul class="pagination">
    
    <li class="page-item">
        <a href="/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a href="" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/4/">4</a></li>
    
    
    <li class="page-item">
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/page/4/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>


        </div>
        
  
  <script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>


    </body>
</html>
